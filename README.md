# FairFace
This project aims to explore stereotype biases in generative artificial intelligence models, with a particular focus on gender, race, and age representations during the text-to-image generation process. We compared the outputs of three models - DALL Â· E3, Dreamlike v2 and Stable Diffusion (SD) - under multiple role prompts: CEO,, and Doctor. ScientistBeautifulPerson

Furthermore, we also explored the effectiveness of prompt engineering in reducing bias by comparing the modified CEO prompt (CEO_V2) with the original prompt (), CEO_V1, and using the same model (based on Dell's model).
